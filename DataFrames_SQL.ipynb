{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL vs Spark\n",
    "\n",
    "Examples borrowed from:\n",
    "    * https://github.com/sbartek/intro-to-pyspark\n",
    "    * https://github.com/carloapp2/SparkPOT.git\n",
    "    \n",
    "See doc on: http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#\n",
    "\n",
    "Data comes from \n",
    "<https://www.kaggle.com/c/competitive-data-science-predict-future-sales/data>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.56.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6dbc572f90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if spark session is defined\n",
    "## Otherwise create one with\n",
    "#from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.appName(\"PySparkShell\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/JulienCojan/pyspark_kschool/master/data/competitive-data-science-predict-future-sales/sales_train.csv.gz -P data/competitive-data-science-predict-future-sales/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MAD', 'Madrid', 'ES', 40.4165, -3.70256),\n",
       " ('BCN', 'Barcelona', 'ES', 41.297078, 2.078464),\n",
       " ('PAR', 'Paris', 'FR', 48.85341, 2.3488),\n",
       " ('ROM', 'Rome', 'IT', 41.89193, 12.51133)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_rdd = sc.parallelize([\n",
    "    (\"MAD\", \"Madrid\", \"ES\", 40.4165, -3.70256),\n",
    "    (\"BCN\", \"Barcelona\", \"ES\", 41.297078, 2.078464),\n",
    "    (\"PAR\", \"Paris\", \"FR\", 48.85341, 2.3488),\n",
    "    (\"ROM\", \"Rome\", \"IT\", 41.89193, 12.51133)])\n",
    "cities_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[city_code: string, city_name: string, country_code: string, latitude: double, longitude: double]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df = cities_rdd.toDF([\"city_code\",\"city_name\",\"country_code\",\"latitude\",\"longitude\"])\n",
    "cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+---------+---------+\n",
      "|city_code|city_name|country_code| latitude|longitude|\n",
      "+---------+---------+------------+---------+---------+\n",
      "|      MAD|   Madrid|          ES|  40.4165| -3.70256|\n",
      "|      BCN|Barcelona|          ES|41.297078| 2.078464|\n",
      "|      PAR|    Paris|          FR| 48.85341|   2.3488|\n",
      "|      ROM|     Rome|          IT| 41.89193| 12.51133|\n",
      "+---------+---------+------------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|city_code|city_name|\n",
      "+---------+---------+\n",
      "|      MAD|   Madrid|\n",
      "|      BCN|Barcelona|\n",
      "|      PAR|    Paris|\n",
      "|      ROM|     Rome|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_df.select(cities_df.city_code,F.col('city_name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[lower(city_code): string, city_name: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.select(F.lower(cities_df.city_code),F.col('city_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower(city_code)</th>\n",
       "      <th>city_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mad</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bcn</td>\n",
       "      <td>Barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>par</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rom</td>\n",
       "      <td>Rome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lower(city_code)  city_name\n",
       "0              mad     Madrid\n",
       "1              bcn  Barcelona\n",
       "2              par      Paris\n",
       "3              rom       Rome"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.select(F.lower(cities_df.city_code),F.col('city_name')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_sdf = spark\\\n",
    "    .read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"data/competitive-data-science-predict-future-sales/sales_train.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- date_block_num: string (nullable = true)\n",
      " |-- shop_id: string (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- item_price: string (nullable = true)\n",
      " |-- item_cnt_day: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|date      |date_block_num|shop_id|item_id|item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|02.01.2013|0             |59     |22154  |999.0     |1.0         |\n",
      "|03.01.2013|0             |25     |2552   |899.0     |1.0         |\n",
      "|05.01.2013|0             |25     |2552   |899.0     |-1.0        |\n",
      "|06.01.2013|0             |25     |2554   |1709.05   |1.0         |\n",
      "|15.01.2013|0             |25     |2555   |1099.0    |1.0         |\n",
      "|10.01.2013|0             |25     |2564   |349.0     |1.0         |\n",
      "|02.01.2013|0             |25     |2565   |549.0     |1.0         |\n",
      "|04.01.2013|0             |25     |2572   |239.0     |1.0         |\n",
      "|11.01.2013|0             |25     |2572   |299.0     |1.0         |\n",
      "|03.01.2013|0             |25     |2573   |299.0     |3.0         |\n",
      "|03.01.2013|0             |25     |2574   |399.0     |2.0         |\n",
      "|05.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|07.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|08.01.2013|0             |25     |2574   |399.0     |2.0         |\n",
      "|10.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|11.01.2013|0             |25     |2574   |399.0     |2.0         |\n",
      "|13.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|16.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|26.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|27.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|09.01.2013|0             |25     |2593   |279.0     |1.0         |\n",
      "|16.01.2013|0             |25     |2604   |299.0     |1.0         |\n",
      "|27.01.2013|0             |25     |2604   |299.0     |1.0         |\n",
      "|27.01.2013|0             |25     |2607   |279.0     |1.0         |\n",
      "|29.01.2013|0             |25     |2607   |279.0     |1.0         |\n",
      "|27.01.2013|0             |25     |2609   |1699.0    |1.0         |\n",
      "|06.01.2013|0             |25     |2548   |1708.95   |1.0         |\n",
      "|26.01.2013|0             |25     |2611   |299.0     |1.0         |\n",
      "|02.01.2013|0             |25     |2546   |299.0     |1.0         |\n",
      "|06.01.2013|0             |25     |2515   |1649.0    |1.0         |\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf.show(30,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2935849"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      date|item_price|\n",
      "+----------+----------+\n",
      "|02.01.2013|     999.0|\n",
      "|03.01.2013|     899.0|\n",
      "|05.01.2013|     899.0|\n",
      "|06.01.2013|   1709.05|\n",
      "|15.01.2013|    1099.0|\n",
      "|10.01.2013|     349.0|\n",
      "|02.01.2013|     549.0|\n",
      "|04.01.2013|     239.0|\n",
      "|11.01.2013|     299.0|\n",
      "|03.01.2013|     299.0|\n",
      "|03.01.2013|     399.0|\n",
      "|05.01.2013|     399.0|\n",
      "|07.01.2013|     399.0|\n",
      "|08.01.2013|     399.0|\n",
      "|10.01.2013|     399.0|\n",
      "|11.01.2013|     399.0|\n",
      "|13.01.2013|     399.0|\n",
      "|16.01.2013|     399.0|\n",
      "|26.01.2013|     399.0|\n",
      "|27.01.2013|     399.0|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf.select(sales_sdf.date,sales_sdf.item_price).limit(20).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>1709.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>1099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.01.2013</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04.01.2013</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.01.2013</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>07.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>08.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27.01.2013</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date item_price\n",
       "0   02.01.2013      999.0\n",
       "1   03.01.2013      899.0\n",
       "2   05.01.2013      899.0\n",
       "3   06.01.2013    1709.05\n",
       "4   15.01.2013     1099.0\n",
       "5   10.01.2013      349.0\n",
       "6   02.01.2013      549.0\n",
       "7   04.01.2013      239.0\n",
       "8   11.01.2013      299.0\n",
       "9   03.01.2013      299.0\n",
       "10  03.01.2013      399.0\n",
       "11  05.01.2013      399.0\n",
       "12  07.01.2013      399.0\n",
       "13  08.01.2013      399.0\n",
       "14  10.01.2013      399.0\n",
       "15  11.01.2013      399.0\n",
       "16  13.01.2013      399.0\n",
       "17  16.01.2013      399.0\n",
       "18  26.01.2013      399.0\n",
       "19  27.01.2013      399.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_sdf.select(sales_sdf.date,sales_sdf.item_price).limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(shop_id='59', item_id='22154')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_sdf[['shop_id','item_id']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_sdf.createOrReplaceTempView(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, date_block_num: string, shop_id: string, item_id: string, item_price: string, item_cnt_day: string]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_10 = spark.sql(\n",
    "\"\"\"\n",
    "SELECT *\n",
    "FROM sales\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "sales_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|      date|date_block_num|shop_id|item_id|item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|02.01.2013|             0|     59|  22154|     999.0|         1.0|\n",
      "|03.01.2013|             0|     25|   2552|     899.0|         1.0|\n",
      "|05.01.2013|             0|     25|   2552|     899.0|        -1.0|\n",
      "|06.01.2013|             0|     25|   2554|   1709.05|         1.0|\n",
      "|15.01.2013|             0|     25|   2555|    1099.0|         1.0|\n",
      "|10.01.2013|             0|     25|   2564|     349.0|         1.0|\n",
      "|02.01.2013|             0|     25|   2565|     549.0|         1.0|\n",
      "|04.01.2013|             0|     25|   2572|     239.0|         1.0|\n",
      "|11.01.2013|             0|     25|   2572|     299.0|         1.0|\n",
      "|03.01.2013|             0|     25|   2573|     299.0|         3.0|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+----------+------------+----------+\n",
      "|  date_str|date_block_num|shop_id|item_id|item_price|item_cnt_day|      date|\n",
      "+----------+--------------+-------+-------+----------+------------+----------+\n",
      "|02.01.2013|             0|     59|  22154|     999.0|         1.0|2013-01-02|\n",
      "|03.01.2013|             0|     25|   2552|     899.0|         1.0|2013-01-03|\n",
      "|05.01.2013|             0|     25|   2552|     899.0|        -1.0|2013-01-05|\n",
      "|06.01.2013|             0|     25|   2554|   1709.05|         1.0|2013-01-06|\n",
      "|15.01.2013|             0|     25|   2555|    1099.0|         1.0|2013-01-15|\n",
      "|10.01.2013|             0|     25|   2564|     349.0|         1.0|2013-01-10|\n",
      "|02.01.2013|             0|     25|   2565|     549.0|         1.0|2013-01-02|\n",
      "|04.01.2013|             0|     25|   2572|     239.0|         1.0|2013-01-04|\n",
      "|11.01.2013|             0|     25|   2572|     299.0|         1.0|2013-01-11|\n",
      "|03.01.2013|             0|     25|   2573|     299.0|         3.0|2013-01-03|\n",
      "|03.01.2013|             0|     25|   2574|     399.0|         2.0|2013-01-03|\n",
      "|05.01.2013|             0|     25|   2574|     399.0|         1.0|2013-01-05|\n",
      "|07.01.2013|             0|     25|   2574|     399.0|         1.0|2013-01-07|\n",
      "|08.01.2013|             0|     25|   2574|     399.0|         2.0|2013-01-08|\n",
      "|10.01.2013|             0|     25|   2574|     399.0|         1.0|2013-01-10|\n",
      "|11.01.2013|             0|     25|   2574|     399.0|         2.0|2013-01-11|\n",
      "|13.01.2013|             0|     25|   2574|     399.0|         1.0|2013-01-13|\n",
      "|16.01.2013|             0|     25|   2574|     399.0|         1.0|2013-01-16|\n",
      "|26.01.2013|             0|     25|   2574|     399.0|         1.0|2013-01-26|\n",
      "|27.01.2013|             0|     25|   2574|     399.0|         1.0|2013-01-27|\n",
      "+----------+--------------+-------+-------+----------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf2 = sales_sdf\\\n",
    "    .withColumnRenamed('date', 'date_str')\\\n",
    "    .withColumn('date', (F.from_unixtime(F.unix_timestamp(F.col('date_str'), 'dd.MM.yyyy'))).cast(DateType()))\n",
    "sales_sdf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_str: string (nullable = true)\n",
      " |-- date_block_num: string (nullable = true)\n",
      " |-- shop_id: string (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- item_price: string (nullable = true)\n",
      " |-- item_cnt_day: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_sdf2.createOrReplaceTempView(\"sales2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT ~ select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|shop_id|item_id|\n",
      "+-------+-------+\n",
      "|     59|  22154|\n",
      "|     25|   2552|\n",
      "|     25|   2552|\n",
      "|     25|   2554|\n",
      "|     25|   2555|\n",
      "|     25|   2564|\n",
      "|     25|   2565|\n",
      "|     25|   2572|\n",
      "|     25|   2572|\n",
      "|     25|   2573|\n",
      "|     25|   2574|\n",
      "|     25|   2574|\n",
      "|     25|   2574|\n",
      "|     25|   2574|\n",
      "|     25|   2574|\n",
      "|     25|   2574|\n",
      "|     25|   2574|\n",
      "|     25|   2574|\n",
      "|     25|   2574|\n",
      "|     25|   2574|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT shop_id, item_id\n",
    "FROM sales\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(shop_id='59', item_id='22154')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_sdf\\\n",
    "   .select(\"shop_id\", \"item_id\")\\\n",
    "   .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|shop_id|\n",
      "+-------+\n",
      "|      7|\n",
      "|     51|\n",
      "|     15|\n",
      "|     54|\n",
      "|     11|\n",
      "|     29|\n",
      "|     42|\n",
      "|      3|\n",
      "|     30|\n",
      "|     34|\n",
      "|     59|\n",
      "|      8|\n",
      "|     22|\n",
      "|     28|\n",
      "|     16|\n",
      "|     35|\n",
      "|     52|\n",
      "|      0|\n",
      "|     47|\n",
      "|     43|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DISTINCT shop_id\n",
    "FROM sales\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|shop_id|item_id|\n",
      "+-------+-------+\n",
      "|     25|   2462|\n",
      "|     25|   5274|\n",
      "|     25|   4910|\n",
      "|     25|   5592|\n",
      "|     24|   5848|\n",
      "|     23|  21336|\n",
      "|     24|   3158|\n",
      "|     25|  13903|\n",
      "|     25|  16890|\n",
      "|     25|  16644|\n",
      "|     25|  16562|\n",
      "|     25|  16457|\n",
      "|     25|  15701|\n",
      "|     25|   8034|\n",
      "|     25|   8831|\n",
      "|     25|   7276|\n",
      "|     25|  11236|\n",
      "|     25|  12133|\n",
      "|     19|  15100|\n",
      "|     19|  14939|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DISTINCT shop_id, item_id\n",
    "FROM sales\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|shop_id|item_id|\n",
      "+-------+-------+\n",
      "|     25|   2462|\n",
      "|     25|   5274|\n",
      "|     25|   4910|\n",
      "|     25|   5592|\n",
      "|     24|   5848|\n",
      "|     23|  21336|\n",
      "|     24|   3158|\n",
      "|     25|  13903|\n",
      "|     25|  16890|\n",
      "|     25|  16644|\n",
      "|     25|  16562|\n",
      "|     25|  16457|\n",
      "|     25|  15701|\n",
      "|     25|   8034|\n",
      "|     25|   8831|\n",
      "|     25|   7276|\n",
      "|     25|  11236|\n",
      "|     25|  12133|\n",
      "|     19|  15100|\n",
      "|     19|  14939|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf\\\n",
    "    .select(\"shop_id\",\"item_id\")\\\n",
    "    .distinct()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__ List distinct values for `date` and `date_block_num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|      date|date_block_num|\n",
      "+----------+--------------+\n",
      "|13.02.2013|             1|\n",
      "|02.04.2013|             3|\n",
      "|22.01.2014|            12|\n",
      "|10.10.2014|            21|\n",
      "|20.07.2015|            30|\n",
      "|27.05.2013|             4|\n",
      "|09.07.2013|             6|\n",
      "|28.01.2014|            12|\n",
      "|28.02.2014|            13|\n",
      "|26.03.2014|            14|\n",
      "|11.07.2013|             6|\n",
      "|01.11.2013|            10|\n",
      "|08.03.2014|            14|\n",
      "|02.04.2014|            15|\n",
      "|06.06.2014|            17|\n",
      "|13.10.2014|            21|\n",
      "|06.12.2014|            23|\n",
      "|28.03.2015|            26|\n",
      "|15.10.2015|            33|\n",
      "|14.07.2013|             6|\n",
      "+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf\\\n",
    "    .select(\"date\",\"date_block_num\")\\\n",
    "    .distinct()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHERE ~ filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|date      |date_block_num|shop_id|item_id|item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|03.01.2013|0             |25     |2552   |899.0     |1.0         |\n",
      "|05.01.2013|0             |25     |2552   |899.0     |-1.0        |\n",
      "|06.01.2013|0             |25     |2554   |1709.05   |1.0         |\n",
      "|15.01.2013|0             |25     |2555   |1099.0    |1.0         |\n",
      "|10.01.2013|0             |25     |2564   |349.0     |1.0         |\n",
      "|02.01.2013|0             |25     |2565   |549.0     |1.0         |\n",
      "|04.01.2013|0             |25     |2572   |239.0     |1.0         |\n",
      "|11.01.2013|0             |25     |2572   |299.0     |1.0         |\n",
      "|03.01.2013|0             |25     |2573   |299.0     |3.0         |\n",
      "|03.01.2013|0             |25     |2574   |399.0     |2.0         |\n",
      "|05.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|07.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|08.01.2013|0             |25     |2574   |399.0     |2.0         |\n",
      "|10.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|11.01.2013|0             |25     |2574   |399.0     |2.0         |\n",
      "|13.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|16.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|26.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|27.01.2013|0             |25     |2574   |399.0     |1.0         |\n",
      "|09.01.2013|0             |25     |2593   |279.0     |1.0         |\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM sales\n",
    "WHERE shop_id = 25\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|      date|date_block_num|shop_id|item_id|item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|03.01.2013|             0|     25|   2552|     899.0|         1.0|\n",
      "|05.01.2013|             0|     25|   2552|     899.0|        -1.0|\n",
      "|06.01.2013|             0|     25|   2554|   1709.05|         1.0|\n",
      "|15.01.2013|             0|     25|   2555|    1099.0|         1.0|\n",
      "|10.01.2013|             0|     25|   2564|     349.0|         1.0|\n",
      "|02.01.2013|             0|     25|   2565|     549.0|         1.0|\n",
      "|04.01.2013|             0|     25|   2572|     239.0|         1.0|\n",
      "|11.01.2013|             0|     25|   2572|     299.0|         1.0|\n",
      "|03.01.2013|             0|     25|   2573|     299.0|         3.0|\n",
      "|03.01.2013|             0|     25|   2574|     399.0|         2.0|\n",
      "|05.01.2013|             0|     25|   2574|     399.0|         1.0|\n",
      "|07.01.2013|             0|     25|   2574|     399.0|         1.0|\n",
      "|08.01.2013|             0|     25|   2574|     399.0|         2.0|\n",
      "|10.01.2013|             0|     25|   2574|     399.0|         1.0|\n",
      "|11.01.2013|             0|     25|   2574|     399.0|         2.0|\n",
      "|13.01.2013|             0|     25|   2574|     399.0|         1.0|\n",
      "|16.01.2013|             0|     25|   2574|     399.0|         1.0|\n",
      "|26.01.2013|             0|     25|   2574|     399.0|         1.0|\n",
      "|27.01.2013|             0|     25|   2574|     399.0|         1.0|\n",
      "|09.01.2013|             0|     25|   2593|     279.0|         1.0|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf\\\n",
    "   .filter(F.col(\"shop_id\") == 25)\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__ List different items from shop 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|item_id|\n",
      "+-------+\n",
      "|2088   |\n",
      "|3210   |\n",
      "|829    |\n",
      "|14899  |\n",
      "|13610  |\n",
      "|17506  |\n",
      "|6613   |\n",
      "|10096  |\n",
      "|11332  |\n",
      "|20158  |\n",
      "|18130  |\n",
      "|18947  |\n",
      "|6194   |\n",
      "|18634  |\n",
      "|19338  |\n",
      "|21331  |\n",
      "|15555  |\n",
      "|17401  |\n",
      "|6240   |\n",
      "|3959   |\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DISTINCT item_id\n",
    "FROM sales\n",
    "WHERE shop_id = 25\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[item_id#35], functions=[])\n",
      "+- Exchange hashpartitioning(item_id#35, 200)\n",
      "   +- *(1) HashAggregate(keys=[item_id#35], functions=[])\n",
      "      +- *(1) Project [item_id#35]\n",
      "         +- *(1) Filter (isnotnull(shop_id#34) && (cast(shop_id#34 as int) = 25))\n",
      "            +- *(1) FileScan csv [shop_id#34,item_id#35] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/mnt/c/Users/jcojan/Documents/Perso/Curso/KSchool/Spark/pyspark_kschool/da..., PartitionFilters: [], PushedFilters: [IsNotNull(shop_id)], ReadSchema: struct<shop_id:string,item_id:string>\n"
     ]
    }
   ],
   "source": [
    "tmp_df = sales_sdf\\\n",
    "   .filter(F.col(\"shop_id\") == 25)\\\n",
    "   .select('item_id')\\\n",
    "   .distinct()\n",
    "tmp_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|item_id|\n",
      "+-------+\n",
      "|   2088|\n",
      "|   3210|\n",
      "|    829|\n",
      "|  14899|\n",
      "|  13610|\n",
      "|  17506|\n",
      "|   6613|\n",
      "|  10096|\n",
      "|  11332|\n",
      "|  20158|\n",
      "|  18130|\n",
      "|  18947|\n",
      "|   6194|\n",
      "|  18634|\n",
      "|  19338|\n",
      "|  21331|\n",
      "|  15555|\n",
      "|  17401|\n",
      "|   6240|\n",
      "|   3959|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [item_id#35]\n",
      "+- *(3) Filter (isnotnull(shop_id#34) && (cast(shop_id#34 as int) = 25))\n",
      "   +- SortAggregate(key=[item_id#35], functions=[first(shop_id#34, false)])\n",
      "      +- *(2) Sort [item_id#35 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(item_id#35, 200)\n",
      "            +- SortAggregate(key=[item_id#35], functions=[partial_first(shop_id#34, false)])\n",
      "               +- *(1) Sort [item_id#35 ASC NULLS FIRST], false, 0\n",
      "                  +- *(1) Project [item_id#35, shop_id#34]\n",
      "                     +- *(1) FileScan csv [shop_id#34,item_id#35] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/mnt/c/Users/jcojan/Documents/Perso/Curso/KSchool/Spark/pyspark_kschool/da..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<shop_id:string,item_id:string>\n"
     ]
    }
   ],
   "source": [
    "tmp_df2 = sales_sdf\\\n",
    "    .select(F.col('item_id'))\\\n",
    "    .distinct()\\\n",
    "    .filter(F.col(\"shop_id\") == 25)\n",
    "tmp_df2.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|item_id|\n",
      "+-------+\n",
      "|  10096|\n",
      "|  11332|\n",
      "|  11563|\n",
      "|  13610|\n",
      "|  14899|\n",
      "|  16576|\n",
      "|  17506|\n",
      "|  20428|\n",
      "|  20512|\n",
      "|   2088|\n",
      "|   2136|\n",
      "|   3210|\n",
      "|   6613|\n",
      "|    829|\n",
      "|  10272|\n",
      "|  10309|\n",
      "|  10603|\n",
      "|  11236|\n",
      "|  12542|\n",
      "|  14218|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORDER BY ~ orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|      date|date_block_num|shop_id|item_id|item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|31.12.2013|            11|     25|   2252|     599.0|         1.0|\n",
      "|30.12.2013|            11|     25|   2252|     599.0|         3.0|\n",
      "|30.08.2013|             7|     25|   2252|     599.0|         1.0|\n",
      "|30.05.2013|             4|     25|   2252|     599.0|         1.0|\n",
      "|30.03.2013|             2|     25|   2252|     599.0|         3.0|\n",
      "|30.01.2013|             0|     25|   2252|     599.0|         1.0|\n",
      "|29.10.2013|             9|     25|   2252|     599.0|         1.0|\n",
      "|29.09.2013|             8|     25|   2252|     599.0|         1.0|\n",
      "|29.08.2013|             7|     25|   2252|     599.0|         1.0|\n",
      "|29.03.2015|            26|     25|   2252|     399.0|         3.0|\n",
      "|29.03.2013|             2|     25|   2252|     599.0|         1.0|\n",
      "|28.12.2013|            11|     25|   2252|     599.0|         1.0|\n",
      "|28.09.2014|            20|     25|   2252|     419.0|         1.0|\n",
      "|28.09.2013|             8|     25|   2252|     599.0|         1.0|\n",
      "|28.03.2013|             2|     25|   2252|     599.0|         1.0|\n",
      "|28.01.2013|             0|     25|   2252|     599.0|         1.0|\n",
      "|27.12.2013|            11|     25|   2252|     599.0|         1.0|\n",
      "|27.10.2013|             9|     25|   2252|     599.0|         1.0|\n",
      "|27.07.2013|             6|     25|   2252|     599.0|         1.0|\n",
      "|26.12.2013|            11|     25|   2252|     599.0|         1.0|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM sales\n",
    "WHERE shop_id = 25 AND item_id = 2252\n",
    "ORDER BY date desc\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|      date|date_block_num|shop_id|item_id|item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|01.02.2013|             1|     25|   2252|     599.0|         1.0|\n",
      "|01.04.2013|             3|     25|   2252|     598.5|         1.0|\n",
      "|01.07.2013|             6|     25|   2252|     599.0|         1.0|\n",
      "|01.07.2015|            30|     25|   2252|     399.0|         1.0|\n",
      "|01.08.2013|             7|     25|   2252|     599.0|         1.0|\n",
      "|02.01.2015|            24|     25|   2252|     399.0|         1.0|\n",
      "|02.05.2013|             4|     25|   2252|     599.0|         1.0|\n",
      "|02.06.2014|            17|     25|   2252|     419.0|         1.0|\n",
      "|02.09.2013|             8|     25|   2252|     599.0|         1.0|\n",
      "|02.11.2013|            10|     25|   2252|     599.0|         1.0|\n",
      "|02.12.2014|            23|     25|   2252|     279.0|         1.0|\n",
      "|03.03.2013|             2|     25|   2252|     599.0|         2.0|\n",
      "|03.05.2013|             4|     25|   2252|     599.0|         1.0|\n",
      "|03.09.2013|             8|     25|   2252|     599.0|         1.0|\n",
      "|03.10.2013|             9|     25|   2252|     599.0|         1.0|\n",
      "|04.01.2015|            24|     25|   2252|     399.0|         1.0|\n",
      "|04.03.2013|             2|     25|   2252|     599.0|         1.0|\n",
      "|04.05.2015|            28|     25|   2252|     399.0|         1.0|\n",
      "|04.10.2014|            21|     25|   2252|     419.0|         1.0|\n",
      "|05.03.2013|             2|     25|   2252|     599.0|         1.0|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf\\\n",
    "   .filter((F.col(\"shop_id\") == 25) & (F.col(\"item_id\") == 2252))\\\n",
    "   .orderBy(\"date\")\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|      date|date_block_num|shop_id|item_id|item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|30.12.2013|            11|     25|   2252|     599.0|         3.0|\n",
      "|29.03.2015|            26|     25|   2252|     399.0|         3.0|\n",
      "|30.03.2013|             2|     25|   2252|     599.0|         3.0|\n",
      "|26.05.2013|             4|     25|   2252|     599.0|         3.0|\n",
      "|16.11.2014|            22|     25|   2252|     419.0|         2.0|\n",
      "|15.03.2013|             2|     25|   2252|     599.0|         2.0|\n",
      "|05.10.2013|             9|     25|   2252|     599.0|         2.0|\n",
      "|10.10.2014|            21|     25|   2252|     419.0|         2.0|\n",
      "|16.08.2015|            31|     25|   2252|     399.0|         2.0|\n",
      "|21.07.2013|             6|     25|   2252|     599.0|         2.0|\n",
      "|03.03.2013|             2|     25|   2252|     599.0|         2.0|\n",
      "|18.04.2014|            15|     25|   2252|     599.0|         2.0|\n",
      "|22.05.2014|            16|     25|   2252|     419.0|         2.0|\n",
      "|07.01.2013|             0|     25|   2252|     599.0|         1.0|\n",
      "|18.01.2013|             0|     25|   2252|     599.0|         1.0|\n",
      "|12.01.2013|             0|     25|   2252|     599.0|         1.0|\n",
      "|21.01.2013|             0|     25|   2252|     599.0|         1.0|\n",
      "|30.01.2013|             0|     25|   2252|     599.0|         1.0|\n",
      "|23.01.2013|             0|     25|   2252|     599.0|         1.0|\n",
      "|01.02.2013|             1|     25|   2252|     599.0|         1.0|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf\\\n",
    "   .filter((F.col(\"shop_id\") == 25) & (F.col(\"item_id\") == 2252))\\\n",
    "   .orderBy(F.desc(\"item_cnt_day\"))\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__ List different items and its price that were sold on 20th or 21st of August 2015 ordered by price starting from the most expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+-------------+------------+\n",
      "|      date|date_block_num|shop_id|item_id|   item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+-------------+------------+\n",
      "|21.08.2015|            31|     31|   1540|       999.75|         2.0|\n",
      "|22.08.2015|            31|     42|   1540|999.666666667|         3.0|\n",
      "|22.08.2015|            31|     14|   1540|        999.5|         1.0|\n",
      "|22.08.2015|            31|     39|   3464|        999.5|         1.0|\n",
      "|22.08.2015|            31|     39|   1557|        999.5|         1.0|\n",
      "|21.08.2015|            31|     57|   2430|        999.5|         1.0|\n",
      "|22.08.2015|            31|     35|   1540|        999.5|         1.0|\n",
      "|22.08.2015|            31|     52|   1540|        999.5|         1.0|\n",
      "|21.08.2015|            31|     57|   2431|        999.5|         1.0|\n",
      "|21.08.2015|            31|     52|   2423|        999.5|         1.0|\n",
      "|22.08.2015|            31|     42|   6503|        999.5|         2.0|\n",
      "|22.08.2015|            31|     49|   6503|        999.5|        12.0|\n",
      "|22.08.2015|            31|     37|   3445|        999.5|         2.0|\n",
      "|22.08.2015|            31|     37|   2423|        999.5|         1.0|\n",
      "|21.08.2015|            31|     52|   1556|        999.5|         1.0|\n",
      "|22.08.2015|            31|     42|   3445|        999.5|         2.0|\n",
      "|22.08.2015|            31|     38|   3464|        999.5|         1.0|\n",
      "|21.08.2015|            31|     52|   2431|        999.5|         1.0|\n",
      "|21.08.2015|            31|     57|   3464|        999.5|         1.0|\n",
      "|21.08.2015|            31|     52|   3445|        999.5|         2.0|\n",
      "+----------+--------------+-------+-------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf\\\n",
    "   .filter((F.col(\"date\") == \"21.08.2015\") | (F.col(\"date\") == \"22.08.2015\"))\\\n",
    "   .orderBy(F.desc(\"item_price\"))\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+-------------+------------+\n",
      "|      date|date_block_num|shop_id|item_id|   item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+-------------+------------+\n",
      "|21.08.2015|            31|     31|   1540|       999.75|         2.0|\n",
      "|22.08.2015|            31|     42|   1540|999.666666667|         3.0|\n",
      "|22.08.2015|            31|     14|   1540|        999.5|         1.0|\n",
      "|22.08.2015|            31|     39|   3464|        999.5|         1.0|\n",
      "|22.08.2015|            31|     39|   1557|        999.5|         1.0|\n",
      "|21.08.2015|            31|     57|   2430|        999.5|         1.0|\n",
      "|22.08.2015|            31|     35|   1540|        999.5|         1.0|\n",
      "|22.08.2015|            31|     52|   1540|        999.5|         1.0|\n",
      "|21.08.2015|            31|     57|   2431|        999.5|         1.0|\n",
      "|21.08.2015|            31|     52|   2423|        999.5|         1.0|\n",
      "|22.08.2015|            31|     42|   6503|        999.5|         2.0|\n",
      "|22.08.2015|            31|     49|   6503|        999.5|        12.0|\n",
      "|22.08.2015|            31|     37|   3445|        999.5|         2.0|\n",
      "|22.08.2015|            31|     37|   2423|        999.5|         1.0|\n",
      "|21.08.2015|            31|     52|   1556|        999.5|         1.0|\n",
      "|22.08.2015|            31|     42|   3445|        999.5|         2.0|\n",
      "|22.08.2015|            31|     38|   3464|        999.5|         1.0|\n",
      "|21.08.2015|            31|     52|   2431|        999.5|         1.0|\n",
      "|21.08.2015|            31|     57|   3464|        999.5|         1.0|\n",
      "|21.08.2015|            31|     52|   3445|        999.5|         2.0|\n",
      "+----------+--------------+-------+-------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf\\\n",
    "   .filter(F.col(\"date\").isin([\"21.08.2015\",\"22.08.2015\"]))\\\n",
    "   .orderBy(F.desc(\"item_price\"))\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+-------------+------------+----------+\n",
      "|  date_str|date_block_num|shop_id|item_id|   item_price|item_cnt_day|      date|\n",
      "+----------+--------------+-------+-------+-------------+------------+----------+\n",
      "|21.08.2015|            31|     31|   1540|       999.75|         2.0|2015-08-21|\n",
      "|22.08.2015|            31|     42|   1540|999.666666667|         3.0|2015-08-22|\n",
      "|22.08.2015|            31|     14|   1540|        999.5|         1.0|2015-08-22|\n",
      "|22.08.2015|            31|     39|   3464|        999.5|         1.0|2015-08-22|\n",
      "|22.08.2015|            31|     39|   1557|        999.5|         1.0|2015-08-22|\n",
      "|21.08.2015|            31|     57|   2430|        999.5|         1.0|2015-08-21|\n",
      "|22.08.2015|            31|     35|   1540|        999.5|         1.0|2015-08-22|\n",
      "|22.08.2015|            31|     52|   1540|        999.5|         1.0|2015-08-22|\n",
      "|21.08.2015|            31|     57|   2431|        999.5|         1.0|2015-08-21|\n",
      "|21.08.2015|            31|     52|   2423|        999.5|         1.0|2015-08-21|\n",
      "|22.08.2015|            31|     42|   6503|        999.5|         2.0|2015-08-22|\n",
      "|22.08.2015|            31|     49|   6503|        999.5|        12.0|2015-08-22|\n",
      "|22.08.2015|            31|     37|   3445|        999.5|         2.0|2015-08-22|\n",
      "|22.08.2015|            31|     37|   2423|        999.5|         1.0|2015-08-22|\n",
      "|21.08.2015|            31|     52|   1556|        999.5|         1.0|2015-08-21|\n",
      "|22.08.2015|            31|     42|   3445|        999.5|         2.0|2015-08-22|\n",
      "|22.08.2015|            31|     38|   3464|        999.5|         1.0|2015-08-22|\n",
      "|21.08.2015|            31|     52|   2431|        999.5|         1.0|2015-08-21|\n",
      "|21.08.2015|            31|     57|   3464|        999.5|         1.0|2015-08-21|\n",
      "|21.08.2015|            31|     52|   3445|        999.5|         2.0|2015-08-21|\n",
      "+----------+--------------+-------+-------+-------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf2\\\n",
    "   .filter(F.col(\"date\").isin([\"2015-08-21\",\"2015-08-22\"]))\\\n",
    "   .orderBy(F.desc(\"item_price\"))\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+-------------+------------+----------+\n",
      "|  date_str|date_block_num|shop_id|item_id|   item_price|item_cnt_day|      date|\n",
      "+----------+--------------+-------+-------+-------------+------------+----------+\n",
      "|01.08.2015|            31|     25|  10213|       9999.0|         1.0|2015-08-01|\n",
      "|04.08.2015|            31|     16|  13398|       9990.0|         1.0|2015-08-04|\n",
      "|13.08.2015|            31|     57|  13398|       9990.0|         1.0|2015-08-13|\n",
      "|12.08.2015|            31|     57|  13398|       9990.0|         1.0|2015-08-12|\n",
      "|04.08.2015|            31|     49|  13398|       9990.0|         1.0|2015-08-04|\n",
      "|30.08.2015|            31|     48|   7935|       9990.0|         1.0|2015-08-30|\n",
      "|19.08.2015|            31|     26|   1540|999.833333333|         3.0|2015-08-19|\n",
      "|20.08.2015|            31|     35|   3445|       999.75|         2.0|2015-08-20|\n",
      "|19.08.2015|            31|      6|   1540|       999.75|         2.0|2015-08-19|\n",
      "|20.08.2015|            31|     25|   1540|       999.75|         2.0|2015-08-20|\n",
      "|21.08.2015|            31|     31|   1540|       999.75|         2.0|2015-08-21|\n",
      "|20.08.2015|            31|     42|   1540|999.666666667|         3.0|2015-08-20|\n",
      "|22.08.2015|            31|     42|   1540|999.666666667|         3.0|2015-08-22|\n",
      "|20.08.2015|            31|     12|   3445|999.666666667|         3.0|2015-08-20|\n",
      "|25.08.2015|            31|     42|   3445|999.583333333|         6.0|2015-08-25|\n",
      "|29.08.2015|            31|     35|   1556|       999.53|         1.0|2015-08-29|\n",
      "|26.08.2015|            31|     42|   2423|        999.5|         1.0|2015-08-26|\n",
      "|19.08.2015|            31|     42|   1557|        999.5|         1.0|2015-08-19|\n",
      "|31.08.2015|            31|     42|   1557|        999.5|         1.0|2015-08-31|\n",
      "|22.08.2015|            31|     42|   3445|        999.5|         2.0|2015-08-22|\n",
      "+----------+--------------+-------+-------+-------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf2\\\n",
    "   .filter((F.year(F.col(\"date\"))==2015) & (F.month(F.col(\"date\"))==8))\\\n",
    "   .orderBy(F.desc(\"item_price\"))\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+-------+----------+------------+----------+\n",
      "|  date_str|date_block_num|shop_id|item_id|item_price|item_cnt_day|      date|\n",
      "+----------+--------------+-------+-------+----------+------------+----------+\n",
      "|31.08.2015|            31|     42|   4261|     299.0|         1.0|2015-08-31|\n",
      "|10.08.2015|            31|     46|  12752|     499.0|         1.0|2015-08-10|\n",
      "|09.08.2015|            31|     46|  13556|    2499.0|         1.0|2015-08-09|\n",
      "|22.08.2015|            31|     46|  12805|     169.0|         1.0|2015-08-22|\n",
      "|08.08.2015|            31|     46|  12828|      99.0|         1.0|2015-08-08|\n",
      "|19.08.2015|            31|     46|  12828|      99.0|         1.0|2015-08-19|\n",
      "|24.08.2015|            31|     46|  12830|     199.0|         1.0|2015-08-24|\n",
      "|21.08.2015|            31|     46|  13594|    2299.0|         1.0|2015-08-21|\n",
      "|15.08.2015|            31|     46|  12889|     229.0|         1.0|2015-08-15|\n",
      "|31.08.2015|            31|     46|  12899|     399.0|         1.0|2015-08-31|\n",
      "|06.08.2015|            31|     46|  12912|     499.0|         1.0|2015-08-06|\n",
      "|14.08.2015|            31|     46|  12912|     499.0|         1.0|2015-08-14|\n",
      "|23.08.2015|            31|     46|  12912|     499.0|         1.0|2015-08-23|\n",
      "|20.08.2015|            31|     46|  12927|      99.0|         1.0|2015-08-20|\n",
      "|18.08.2015|            31|     46|  12935|     299.0|         1.0|2015-08-18|\n",
      "|28.08.2015|            31|     46|  12935|     299.0|         1.0|2015-08-28|\n",
      "|19.08.2015|            31|     46|  12964|     229.0|         1.0|2015-08-19|\n",
      "|18.08.2015|            31|     46|  12970|     229.0|         1.0|2015-08-18|\n",
      "|24.08.2015|            31|     46|  12970|     229.0|         1.0|2015-08-24|\n",
      "|18.08.2015|            31|     46|  12974|     249.0|         1.0|2015-08-18|\n",
      "+----------+--------------+-------+-------+----------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "select *\n",
    "from sales2\n",
    "where year(date)=2015 and month(date)=8\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AS ~ alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-------+\n",
      "|item_cnt_day|item_price|revenue|\n",
      "+------------+----------+-------+\n",
      "|         1.0|     999.0|  999.0|\n",
      "|         1.0|     899.0|  899.0|\n",
      "|        -1.0|     899.0| -899.0|\n",
      "|         1.0|   1709.05|1709.05|\n",
      "|         1.0|    1099.0| 1099.0|\n",
      "|         1.0|     349.0|  349.0|\n",
      "|         1.0|     549.0|  549.0|\n",
      "|         1.0|     239.0|  239.0|\n",
      "|         1.0|     299.0|  299.0|\n",
      "|         3.0|     299.0|  897.0|\n",
      "|         2.0|     399.0|  798.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         2.0|     399.0|  798.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         2.0|     399.0|  798.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "+------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT item_cnt_day\n",
    ",   item_price\n",
    ",   item_cnt_day * item_price AS revenue\n",
    "FROM sales\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-------+\n",
      "|item_cnt_day|item_price|revenue|\n",
      "+------------+----------+-------+\n",
      "|         1.0|     999.0|  999.0|\n",
      "|         1.0|     899.0|  899.0|\n",
      "|        -1.0|     899.0| -899.0|\n",
      "|         1.0|   1709.05|1709.05|\n",
      "|         1.0|    1099.0| 1099.0|\n",
      "|         1.0|     349.0|  349.0|\n",
      "|         1.0|     549.0|  549.0|\n",
      "|         1.0|     239.0|  239.0|\n",
      "|         1.0|     299.0|  299.0|\n",
      "|         3.0|     299.0|  897.0|\n",
      "|         2.0|     399.0|  798.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         2.0|     399.0|  798.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         2.0|     399.0|  798.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "|         1.0|     399.0|  399.0|\n",
      "+------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_sdf\\\n",
    "    .select(\n",
    "        F.col(\"item_cnt_day\"),\n",
    "        F.col(\"item_price\"),\n",
    "        (F.col(\"item_cnt_day\") * F.col(\"item_price\")).alias(\"revenue\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT AVG(item_cnt_day) AS mean_sale\n",
    ",   STDDEV(item_cnt_day) AS sd_sales\n",
    ",   SUM(item_cnt_day) AS sum_sales\n",
    ",   COUNT(*) AS nitems\n",
    "FROM sales\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_sdf\\\n",
    "    .select(\n",
    "        F.mean(F.col(\"item_cnt_day\")).alias(\"mean_sales\"),\n",
    "        F.stddev(F.col(\"item_cnt_day\")).alias(\"sd_sales\"),\n",
    "        F.sum(F.col(\"item_cnt_day\")).alias(\"sum_sales\"),\n",
    "        F.count(F.col(\"item_cnt_day\")).alias(\"n_items\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__ What is mean, standard deviation and median of the number of sold items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GROUP BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT date_format(from_unixtime(unix_timestamp(date, 'dd.MM.yyyy')), \"yyyy-MM-dd\") AS date\n",
    ",   SUM(item_cnt_day) AS items_sold\n",
    "FROM sales\n",
    "GROUP BY date\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [20, 10]\n",
    "matplotlib.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT date_format(from_unixtime(unix_timestamp(date, 'dd.MM.yyyy')), \"yyyy-MM-dd\") AS date\n",
    ",   SUM(item_cnt_day) AS items_sold\n",
    "FROM sales\n",
    "GROUP BY date\n",
    "\"\"\").toPandas()\\\n",
    "    .set_index(\"date\")['items_sold'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_sdf\\\n",
    "    .withColumn(\"date\", F.unix_timestamp(F.col(\"date\"), 'dd.MM.yyyy'))\\\n",
    "    .groupBy(F.col(\"date\"))\\\n",
    "    .agg(F.sum(F.col(\"item_cnt_day\")).alias(\"items_sold\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__ For each day what is total daily revenue? Output table should have columns `date`, `total_revenue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_sdf = spark.read.option(\"header\", \"true\").csv(\"data/shops.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_sdf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_sdf.createOrReplaceTempView(\"shops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT sales.shop_id\n",
    ",   shops.shop_name\n",
    "FROM (\n",
    "    SELECT DISTINCT shop_id\n",
    "    FROM sales)  sales\n",
    "LEFT JOIN shops\n",
    "ON sales.shop_id == shops.shop_id\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_sdf\\\n",
    "    .select(\"shop_id\")\\\n",
    "    .distinct()\\\n",
    "    .join(shops_sdf, \"shop_id\", how=\"left\")\\\n",
    "    .select(\"shop_id\", \"shop_name\")\\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__ Find a product with highest sell. What is its name? (hint use `items.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with cache\n",
    "# example using struct data\n",
    "# example using subqueries (explicit or as two dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__ For each day in August 2015 find shop name with maximal sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window functions\n",
    "\n",
    "First let's correct the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    ",   date_format(from_unixtime(unix_timestamp(date, 'dd.MM.yyyy')), \"yyyy-MM-dd\") AS date_iso\n",
    "FROM sales\n",
    "\"\"\").createOrReplaceTempView(\"sales_iso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_iso_sdf = sales_sdf\\\n",
    "    .withColumn(\n",
    "    \"date_iso\", \n",
    "    F.unix_timestamp(F.col(\"date\"), 'dd.MM.yyyy'))\n",
    "sales_iso_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT shop_id\n",
    ",   item_id\n",
    ",   date_iso\n",
    ",   item_cnt_day\n",
    ",   LEAD(item_cnt_day) OVER \n",
    "        (PARTITION BY shop_id, item_id ORDER BY date_iso) as lead_item_cnt_day\n",
    "FROM sales_iso\n",
    "ORDER BY shop_id\n",
    ",   item_id\n",
    ",   date_iso\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "sales_iso_sdf.select(\n",
    "    F.col(\"shop_id\"),   \n",
    "    F.col(\"item_id\"),   \n",
    "    F.col(\"date_iso\"),   \n",
    "    F.col(\"item_cnt_day\"),   \n",
    "    F.lead(F.col(\"item_cnt_day\"))\\\n",
    "        .over(Window.partitionBy(\"shop_id\", \"item_id\").orderBy('date_iso'))\\\n",
    "        .alias(\"lead_item_cnt_day\")\n",
    ").orderBy(\"shop_id\", \"item_id\", \"date_iso\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(\"shop_id\", \"item_id\").orderBy('date_iso')\n",
    "\n",
    "sales_iso_sdf.select(\n",
    "    F.col(\"shop_id\"),   \n",
    "    F.col(\"item_id\"),   \n",
    "    F.col(\"date_iso\"),   \n",
    "    F.col(\"item_cnt_day\"),   \n",
    "    F.lead(F.col(\"item_cnt_day\"))\\\n",
    "        .over(window)\\\n",
    "        .alias(\"lead_item_cnt_day\")\n",
    ").orderBy(\"shop_id\", \"item_id\", \"date_iso\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__ What is moving average (+-3 days) of total daily revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Exercises\n",
    "\n",
    "* Which shop had the highest sells in August 2015. What was his name?\n",
    "* What is the name of category of with the highest monthly sells. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame as an RDD of Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sales_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = sales_sdf.first()\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row.date)\n",
    "print(row['date_block_num'])\n",
    "row.asDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_sdf.rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales_sdf.rdd.toDebugString().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_per_day = sales_sdf\\\n",
    "    .groupBy(F.col(\"date\"))\\\n",
    "    .agg(F.sum(F.col(\"item_cnt_day\")))\n",
    "\n",
    "print(sales_per_day.rdd.toDebugString().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
