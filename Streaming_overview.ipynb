{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured streaming\n",
    "## packages\n",
    "* pyspark.streaming -> streaming to RDD\n",
    "* pyspark.sql.streaming -> streaming to DataFrames (focusing on this one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuentes\n",
    "Las fuentes de datos en streaming pueden ser:\n",
    "* Kafka\n",
    "* carpetas (incrementos en archivos nuevos)\n",
    "* socket (para pruebas)\n",
    "* rate (generador de lineas, par puebas y debugging)\n",
    "\n",
    "## Salidas\n",
    "El resultado de un DataFrame en streaming se puede grabar en :\n",
    "* Console (para pruebas)\n",
    "* Archivos\n",
    "* Kafka\n",
    "* Memoria (para consultar el contenido con otras queries)\n",
    "* Foreach... (actionnes)\n",
    "\n",
    "Varios modos de salida:\n",
    "* \"*Complete*\" (no disponible con salida en Archivos)\n",
    "* \"*Append*\"\n",
    "* \"*Update*\"  (no disponible con salida en Archivos ni en memoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuente CSV\n",
    "En este ejemplo, ir a√±adiendp archivos en la carpeta \"stream_input/\". Las modificaciones a archivos ya leidos no se tomaran en cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "userSchema = StructType().\\\n",
    "    add(\"time\", \"timestamp\").\\\n",
    "    add(\"item\", \"integer\").\\\n",
    "    add(\"nb_sales\", \"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDF = spark \\\n",
    "    .readStream \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .schema(userSchema) \\\n",
    "    .csv(\"data/streaming/stream_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(csvDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvStream = csvDF.writeStream. \\\n",
    "outputMode(\"append\"). \\\n",
    "format(\"console\"). \\\n",
    "start() # outputs in the bash console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvStream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memStream = csvDF.writeStream. \\\n",
    "outputMode(\"append\"). \\\n",
    "format(\"memory\").\\\n",
    "queryName(\"sales\").\\\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select * from sales\").show() # after a file was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memStream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvStream = csvDF. \\\n",
    "    writeStream. \\\n",
    "    outputMode(\"append\"). \\\n",
    "    format(\"csv\"). \\\n",
    "    option(\"checkpointLocation\", \"checkpoint_dir\").\\\n",
    "    option(\"path\", \"output/\").\\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvStream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuente socket\n",
    "En linea de comando ejecutar ```nc -lk 9999``` lo que envia cada linea de lo que se escribe por el puerto 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socDF = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\",\"localhost\") \\\n",
    "    .option(\"port\",9999).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = socDF.\\\n",
    "    writeStream. \\\n",
    "    outputMode(\"append\"). \\\n",
    "    format(\"console\"). \\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDF = socDF.\\\n",
    "    withColumn(\"values\",F.split(socDF[\"value\"],\";\")).\\\n",
    "    withColumn(\"time\",F.col(\"values\")[0].cast(\"timestamp\")).\\\n",
    "    withColumn(\"item\",F.col(\"values\")[1].cast(\"integer\")).\\\n",
    "    withColumn(\"nb_sales\",F.col(\"values\")[2].cast(\"integer\")).\\\n",
    "    select(\"time\", \"item\", \"nb_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = csvDF.\\\n",
    "    writeStream. \\\n",
    "    outputMode(\"append\"). \\\n",
    "    format(\"console\"). \\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = csvDF. \\\n",
    "    writeStream. \\\n",
    "    outputMode(\"append\"). \\\n",
    "    format(\"csv\"). \\\n",
    "    option(\"checkpointLocation\", \"checkpoint_dir\").\\\n",
    "    option(\"path\", \"output/\").\\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones\n",
    "* SQL: select, filter, groupBy\n",
    "* join\n",
    "    * con una fuente estatica: nada obligatorio, watermarking ayuda a contener el uso de memoria\n",
    "    * con otra fuente streaming: limitaciones con obligacion a uso de watermarking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesTot = csvDF.select(F.sum(csvDF.nb_sales).alias(\"nb_sales\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggStream = salesTot.writeStream. \\\n",
    "outputMode(\"complete\"). \\\n",
    "format(\"console\"). \\\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggStream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesPerItem = csvDF\\\n",
    "    .groupBy(csvDF.item)\\\n",
    "    .agg(F.sum(csvDF.nb_sales).alias(\"nb_sales\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggStream = salesPerItem.writeStream. \\\n",
    "outputMode(\"complete\"). \\\n",
    "format(\"console\"). \\\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggStream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = csvDF.withWatermark(\"time\", \"5 minutes\").writeStream. \\\n",
    "outputMode(\"append\"). \\\n",
    "format(\"csv\"). \\\n",
    "option(\"checkpointLocation\", \"checkpoint_dir\").\\\n",
    "option(\"path\", \"output/\").\\\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = csvDF.withWatermark(\"time\", \"5 minutes\").writeStream. \\\n",
    "outputMode(\"append\"). \\\n",
    "format(\"console\"). \\\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowedSales = csvDF.\\\n",
    "withWatermark(\"time\", \"10 minutes\").\\\n",
    "groupBy(\n",
    "  F.window(\"time\", \"5 minutes\", \"5 minutes\"),\n",
    "  \"item\"\n",
    ").agg(F.sum(csvDF.nb_sales).alias(\"nb_sales\")).\\\n",
    "select(\n",
    "    F.col(\"window.start\").alias(\"start\"),\n",
    "    F.col(\"window.end\").alias(\"end\"),\n",
    "    \"item\",\n",
    "    \"nb_sales\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = windowedSales.writeStream. \\\n",
    "outputMode(\"complete\"). \\\n",
    "format(\"console\"). \\\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = windowedSales. \\\n",
    "    writeStream. \\\n",
    "    outputMode(\"append\"). \\\n",
    "    format(\"csv\"). \\\n",
    "    option(\"checkpointLocation\", \"checkpoint_dir\").\\\n",
    "    option(\"path\", \"output/\").\\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemDF = spark.createDataFrame([(1, \"patatas\"), (2, \"jamon\"), (3, \"pimientos\")], [\"item_id\", \"item_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichedDF = csvDF.join(itemDF, csvDF.item==itemDF.item_id, \"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = enrichedDF.writeStream. \\\n",
    "outputMode(\"append\"). \\\n",
    "format(\"console\"). \\\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join with stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cajaSchema = StructType().\\\n",
    "    add(\"time\", \"timestamp\").\\\n",
    "    add(\"item\", \"integer\").\\\n",
    "    add(\"amount\", \"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cajaDF = spark \\\n",
    "    .readStream \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .schema(cajaSchema) \\\n",
    "    .csv(\"data/streaming/caja/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ventaConSaldo = csvDF.alias(\"ventas\").\\\n",
    "    join(cajaDF.withWatermark(\"time\", \"10 minutes\").alias(\"caja\"), \n",
    "           F.expr(\"\"\"caja.item=ventas.item AND \n",
    "            caja.time >= ventas.time AND \n",
    "            caja.time <= ventas.time + interval 5 minutes\"\"\"), \n",
    "           \"full_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = ventaConSaldo.writeStream. \\\n",
    "outputMode(\"append\"). \\\n",
    "format(\"console\"). \\\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
